---
title: 数据挖掘实战（五）：模型融合-二手车价格预测
date: 2020-04-04
permalink: /data-mining-practice-five.html
tags:
 - 数据挖掘
 - 二手车价格预测 
categories:
 - 数据挖掘
---






## 问题记录

Q1：K折交叉验证的过程明白，但是如何达到减小过拟合的问题呢？ A1：如果不使用交叉验证： 1\.
最终模型与参数的选取将极大程度依赖于你对训练集和测试集的划分方法 2\. 只用了部分数据进行模型的训练 3\. 因此使用交叉验证，可以提高了模型的泛化能力

## 模型融合目标

对于多种调参完成的模型进行模型融合

## 内容介绍

  1. 简单加权融合： 

    * 回归：算术平均融合（n个数据叠加除以n），集合平均融合（n个数据相乘后开n次方）
    * 分类：投票
    * 综合：排序融合，log融合
    * 补充：回归也叫分类概率，分类模型的预测值为结果为某一分类结果的概率
  2. stacking/blending（堆放/混合）： 

    * 构建多层模型，次级模型利用初级模型的预测结果再拟合预测
  3. boosting/bagging（在xgboost，Adaboost，GBDT中已经用到） 

    * 多树的提升方法

## Stacking相关理论

  1. 概念介绍 

    * 简单来说 stacking 就是当用初始训练数据学习出若干个基学习器后，将这几个学习器的预测结果作为新的训练集，来学习一个新的学习器。
    * 在stacking方法中，我们把个体学习器叫做初级学习器，用于结合的学习器叫做次级学习器或元学习器（meta-learner），次级学习器用于训练的数据叫做次级训练集。次级训练集是在训练集上用初级学习器得到的。
  2. 方法讲解 

    * 对于二级Stacking分析
    * 以train集和真实的标签列训练，得到个体模型，用此模型对train和test集进行预测，得到标签列P1，T1
    * 同理得到P2,T2
    * 将P1，P2，T1，T2分别合并，得到新的训练集train2和新的测试集test2
    * 以train2为特征，train中的真实标签训练，得到次级模型，将test2输入模型，得到最终的标签列Ypre
  3. 问题讲解 

    * 接这样有时对于如果训练集和测试集分布不那么一致的情况下是有一点问题
    * 在于用初始模型训练的标签再利用真实标签进行再训练，毫无疑问会导致一定的模型过拟合训练集
    * 模型在测试集上的泛化能力或者说效果会有一定的下降
  4. 问题解决 

    * 次级模型尽量选择简单的线性模型
    * 利用K折交叉验证

## 代码示例

### 回归融合

  1. 简单加权平均，结果直接融合


​    
    ## 生成一些简单的样本数据，test_prei 代表第i个模型的预测值
    test_pre1 = [1.2, 3.2, 2.1, 6.2]
    test_pre2 = [0.9, 3.1, 2.0, 5.9]
    test_pre3 = [1.1, 2.9, 2.2, 6.0]
    
    # y_test_true 代表第模型的真实值
    y_test_true = [1, 3, 2, 6] 


​    
​    
    import numpy as np
    import pandas as pd
    import warnings
    warnings.filterwarnings('ignore')
    
    # 定义结果的加权平均函数
    def Weighted_method(test_pre1, test_pre2, test_pre3, w=[1/3, 1/3, 1/3]):
        Weighted_result = w[0]*pd.Series(test_pre1)+w[1]*pd.Series(test_pre2)+w[2]*pd.Series(test_pre3)
        return Weighted_result


​    
​    
​    
    from sklearn import metrics
    print('Pred1 MAE:', metrics.mean_absolute_error(y_test_true, test_pre1))
    print('Pred2 MAE:', metrics.mean_absolute_error(y_test_true, test_pre2))
    print('Pred3 MAE:', metrics.mean_absolute_error(y_test_true, test_pre3))


​    
​    
​    
    Pred1 MAE: 0.1750000000000001
    Pred2 MAE: 0.07499999999999993
    Pred3 MAE: 0.10000000000000009


​    
​    
    # 根据加权计算MAE
    w = [0.3, 0.4, 0.3]
    Weighted_pre = Weighted_method(test_pre1, test_pre2, test_pre3, w)
    print('Weighted_pre MAE:',metrics.mean_absolute_error(y_test_true, Weighted_pre))


​    
​    
​    
    Weighted_pre MAE: 0.05750000000000027


可见，单个模型的最小MAE为0.07，而简单加权后的融合模型的MAE为0.06，有了提升。还有其他一些平均加权的方式，比如各个模型对应的各个label取平均或者取中位数。


​    
    def Mean_method(test_pre1,test_pre2,test_pre3):
        Mean_result = pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),
                                 pd.Series(test_pre3)], axis=1).mean(axis=1)
        return Mean_result


​    
​    
    Mean_pre = Mean_method(test_pre1,test_pre2,test_pre3)
    print('Mean_pre MAE:',metrics.mean_absolute_error(y_test_true, Mean_pre))


​    
​    
    Mean_pre MAE: 0.06666666666666693


​    
​    
    ## 定义结果的加权平均函数
    def Median_method(test_pre1,test_pre2,test_pre3):
        Median_result = pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).median(axis=1)
        return Median_result


​    
​    
    Median_pre = Median_method(test_pre1,test_pre2,test_pre3)
    print('Median_pre MAE:',metrics.mean_absolute_error(y_test_true, Median_pre))


​    
​    
    Median_pre MAE: 0.07500000000000007


  2. Stacking融合（回归）


​    
    from sklearn import linear_model
    
    def Stacking_method(train_reg1, train_reg2, train_reg3, y_train_true,
                       test_pre1, test_pre2, test_pre3, 
                        model_L2=linear_model.LinearRegression()):
        model_L2.fit(pd.concat([pd.Series(train_reg1), pd.Series(train_reg2),
                               pd.Series(train_reg3)], axis=1).values, y_train_true)
        Stacking_result = model_L2.predict(pd.concat([pd.Series(test_pre1), pd.Series(test_pre2),
                                                     pd.Series(test_pre3)],axis=1).values)
        return Stacking_result


​    
​    
    ## 生成一些简单的样本数据，test_prei 代表第i个模型的预测值
    train_reg1 = [3.2, 8.2, 9.1, 5.2]
    train_reg2 = [2.9, 8.1, 9.0, 4.9]
    train_reg3 = [3.1, 7.9, 9.2, 5.0]
    # y_test_true 代表第模型的真实值
    y_train_true = [3, 8, 9, 5] 
    
    test_pre1 = [1.2, 3.2, 2.1, 6.2]
    test_pre2 = [0.9, 3.1, 2.0, 5.9]
    test_pre3 = [1.1, 2.9, 2.2, 6.0]
    
    # y_test_true 代表第模型的真实值
    y_test_true = [1, 3, 2, 6] 


​    
​    
​    
    model_L2 = linear_model.LinearRegression()
    Stacking_pre = Stacking_method(train_reg1,train_reg2,train_reg3,y_train_true,
                                   test_pre1,test_pre2,test_pre3,model_L2)
    print('Stacking_pre MAE:',metrics.mean_absolute_error(y_test_true, Stacking_pre))


​    
​    
    Stacking_pre MAE: 0.04213483146067476


此处采用线性回归模型作为次级模型，对于第二层Stacking的模型不宜选取的过于复杂，这样会导致模型在训练集上过拟合，从而使得在测试集上并不能达到很好的效果。

### 分类模型融合


​    
    from sklearn.datasets import make_blobs
    from sklearn import datasets
    from sklearn.tree import DecisionTreeClassifier
    import numpy as np
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.ensemble import VotingClassifier
    from xgboost import XGBClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.model_selection import train_test_split
    from sklearn.datasets import make_moons
    from sklearn.metrics import accuracy_score,roc_auc_score
    from sklearn.model_selection import cross_val_score
    from sklearn.model_selection import StratifiedKFold


  1. Voting投票机制 

    * Voting即投票机制，分为软投票和硬投票两种，其原理采用少数服从多数的思想。
    * 软投票：和硬投票原理相同，增加了设置权重的功能，可以为不同模型设置不同权重，进而区别模型不同的重要度。
    * 硬投票：对多个模型直接进行投票，不区分模型结果的相对重要度，最终投票数最多的类为最终被预测的类。


​    
​    
    # 硬投票
    iris = datasets.load_iris()
    
    x = iris.data
    y = iris.target
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)
    
    clf1 = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=3, min_child_weight=2,
                        subsample=0.7, colsample_bytree=0.6, object='binary:logistic')
    clf2 = RandomForestClassifier(n_estimators=50, max_depth=1, min_samples_split=4,
                                 min_samples_leaf=63, oob_score=True)
    clf3 = SVC(C=0.1)
    
    eclf = VotingClassifier(estimators=[('xgb',clf1),('rf',clf2),('svc',clf3)], voting='hard')
    for clf, label in zip([clf1, clf2, clf3, eclf], ['XGBBoosting', 'Random Forest', 'SVM', 'Ensemble']):
        scores = cross_val_score(clf, x, y, cv=5, scoring='accuracy')
        print("Accuracy: %0.2f (+/- %0.2f) [%s]" % (scores.mean(), scores.std(), label))


​    
​    
    Accuracy: 0.96 (+/- 0.02) [XGBBoosting]
    Accuracy: 0.33 (+/- 0.00) [Random Forest]
    Accuracy: 0.95 (+/- 0.03) [SVM]
    Accuracy: 0.95 (+/- 0.03) [Ensemble]


​    
​    
    # 软投票
    x=iris.data
    y=iris.target
    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)
    
    clf1 = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=3, min_child_weight=2, subsample=0.8,
                         colsample_bytree=0.8, objective='binary:logistic')
    clf2 = RandomForestClassifier(n_estimators=50, max_depth=1, min_samples_split=4,
                                  min_samples_leaf=63,oob_score=True)
    clf3 = SVC(C=0.1, probability=True)
    
    # 软投票
    eclf = VotingClassifier(estimators=[('xgb', clf1), ('rf', clf2), ('svc', clf3)], voting='soft', weights=[2, 1, 1])
    clf1.fit(x_train, y_train)
    
    for clf, label in zip([clf1, clf2, clf3, eclf], ['XGBBoosting', 'Random Forest', 'SVM', 'Ensemble']):
        scores = cross_val_score(clf, x, y, cv=5, scoring='accuracy')
        print("Accuracy: %0.2f (+/- %0.2f) [%s]" % (scores.mean(), scores.std(), label))


​    
​    
    Accuracy: 0.96 (+/- 0.02) [XGBBoosting]
    Accuracy: 0.33 (+/- 0.00) [Random Forest]
    Accuracy: 0.95 (+/- 0.03) [SVM]
    Accuracy: 0.96 (+/- 0.02) [Ensemble]


  2. 分类的Stacking


​    
    '''
    5-Fold Stacking
    '''
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.ensemble import ExtraTreesClassifier,GradientBoostingClassifier
    import pandas as pd
    #创建训练的数据集
    iris = datasets.load_iris()
    data_0 = iris.data
    data = data_0[:100,:]
    print(data.shape)
    target_0 = iris.target
    target = target_0[:100]
    print(target.shape)


​    
​    
​    
    (100, 4)
    (100,)


​    
​    
    #模型融合中使用到的各个单模型
    clfs = [LogisticRegression(solver='lbfgs'),
            RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),
            ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),
            ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),
            GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]
    
    #切分一部分数据作为测试集
    X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)
    
    dataset_blend_train = np.zeros((X.shape[0], len(clfs)))
    dataset_blend_test = np.zeros((X_predict.shape[0], len(clfs)))
    
    print(dataset_blend_train.shape)
    print(dataset_blend_test.shape)


​    
​    
    (70, 5)
    (30, 5)


​    
​    
    #5折stacking
    # n_splits = 5
    # skf = StratifiedKFold(n_splits)
    # skf = skf.split(X, y)


​    
​    
    # 依次训练各个单模型
    for j, clf in enumerate(clfs):  # 索引和对应的模型
        print('='*30, '\n', j)
        dataset_blend_test_j = np.zeros((X_predict.shape[0], 5))  # shape:(30, 5)
    
        n_splits = 5
        skf = StratifiedKFold(n_splits)
        skf = skf.split(X, y)
    
        # 5-Fold交叉训练
        for i, (train, test) in enumerate(skf):  # 总样本数100，train样本70，五折后分成56个样本训练和14个样本验证 
            X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]  # train和test对应样本的索引
            clf.fit(X_train, y_train)
            y_submission = clf.predict_proba(X_test)[:, 1]  # 预测的各个标签值为1的概率
            dataset_blend_train[test, j] = y_submission  # dataset_blend_train有5列，将y_submission存储到第j列的对应test索引中
            dataset_blend_test_j[:, i] = clf.predict_proba(X_predict)[:, 1]
        #对于测试集，直接用这k个模型的预测值均值作为新的特征。
        dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)  # mean()中的1表示求每一行的均值
    
        print("val auc Score: %f" % roc_auc_score(y_predict, dataset_blend_test[:, j]))


​    
​    
​    
​    
    ============================== 
     0
    val auc Score: 1.000000
    ============================== 
     1
    val auc Score: 1.000000
    ============================== 
     2
    val auc Score: 1.000000
    ============================== 
     3
    val auc Score: 1.000000
    ============================== 
     4
    val auc Score: 1.000000


​    
​    
    clf = LogisticRegression(solver='lbfgs')
    clf.fit(dataset_blend_train, y)
    y_submission = clf.predict_proba(dataset_blend_test)[:, 1]
    
    print("Val auc Score of Stacking: %f" % (roc_auc_score(y_predict, y_submission)))


​    
​    
    Val auc Score of Stacking: 1.000000


  3. Blending 

    * 直接看程序比较清楚
    * 优点： 
      * 比stacking简单（因为不用进行k次的交叉验证来获得stacker feature）
      * 避开了一个信息泄露问题：generlizers和stacker使用了不一样的数据集
    * 缺点： 
      * 使用了很少的数据
      * blender可能会过拟合
      * stacking使用多次的交叉验证会比较稳健


​    
​    
    #创建训练的数据集
    #创建训练的数据集
    data_0 = iris.data
    data = data_0[:100,:]
    
    target_0 = iris.target
    target = target_0[:100]
    
    #模型融合中使用到的各个单模型
    clfs = [LogisticRegression(solver='lbfgs'),
            RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),
            RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),
            ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),
            #ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),
            GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]
    
    #切分一部分数据作为测试集
    X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)
    
    #切分训练数据集为d1,d2两部分
    X_d1, X_d2, y_d1, y_d2 = train_test_split(X, y, test_size=0.5, random_state=2020)
    dataset_d1 = np.zeros((X_d2.shape[0], len(clfs)))
    dataset_d2 = np.zeros((X_predict.shape[0], len(clfs)))
    
    for j, clf in enumerate(clfs):
        #依次训练各个单模型
        clf.fit(X_d1, y_d1)
        y_submission = clf.predict_proba(X_d2)[:, 1]  # 验证集的预测
        dataset_d1[:, j] = y_submission
        #对于测试集，直接用这k个模型的预测值作为新的特征。
        dataset_d2[:, j] = clf.predict_proba(X_predict)[:, 1]  # 测试集的预测
        print("val auc Score: %f" % roc_auc_score(y_predict, dataset_d2[:, j]))
    
    #融合使用的模型
    clf = GradientBoostingClassifier(learning_rate=0.02, subsample=0.5, max_depth=6, n_estimators=30)
    clf.fit(dataset_d1, y_d2)  # 验证集的预测值与实际标签值
    y_submission = clf.predict_proba(dataset_d2)[:, 1]  # 用测试集的预测值预测
    print("Val auc Score of Blending: %f" % (roc_auc_score(y_predict, y_submission)))


​    
​    
​    
    val auc Score: 1.000000
    val auc Score: 1.000000
    val auc Score: 1.000000
    val auc Score: 1.000000
    val auc Score: 1.000000
    Val auc Score of Blending: 1.000000


  4. 分类的Stacking融合

利用mlxtend，直接从其中引入StackingClassifier，以及画图


​    
    import warnings
    warnings.filterwarnings('ignore')
    import itertools
    import numpy as np
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.gridspec as gridspec
    
    from sklearn import datasets
    from sklearn.linear_model import LogisticRegression
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.naive_bayes import GaussianNB 
    from sklearn.ensemble import RandomForestClassifier
    from mlxtend.classifier import StackingClassifier
    
    from sklearn.model_selection import cross_val_score
    from mlxtend.plotting import plot_learning_curves
    from mlxtend.plotting import plot_decision_regions
    
    # 以python自带的鸢尾花数据集为例
    iris = datasets.load_iris()
    X, y = iris.data[:, 1:3], iris.target
    
    clf1 = KNeighborsClassifier(n_neighbors=1)  # KNN
    clf2 = RandomForestClassifier(random_state=1)  # 随机森林
    clf3 = GaussianNB()  # 朴素贝叶斯
    lr = LogisticRegression()
    sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], 
                              meta_classifier=lr)
    
    label = ['KNN', 'Random Forest', 'Naive Bayes', 'Stacking Classifier']
    clf_list = [clf1, clf2, clf3, sclf]
    
    fig = plt.figure(figsize=(10,8))
    gs = gridspec.GridSpec(2, 2)
    grid = itertools.product([0,1],repeat=2)
    
    clf_cv_mean = []
    clf_cv_std = []
    for clf, label, grd in zip(clf_list, label, grid):
    
        scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')
        print("Accuracy: %.2f (+/- %.2f) [%s]" %(scores.mean(), scores.std(), label))
        clf_cv_mean.append(scores.mean())
        clf_cv_std.append(scores.std())
    
        clf.fit(X, y)
        ax = plt.subplot(gs[grd[0], grd[1]])
        fig = plot_decision_regions(X=X, y=y, clf=clf)
        plt.title(label)
    
    plt.show()


​    
​    
    Accuracy: 0.91 (+/- 0.01) [KNN]
    Accuracy: 0.93 (+/- 0.05) [Random Forest]
    Accuracy: 0.92 (+/- 0.03) [Naive Bayes]
    Accuracy: 0.95 (+/- 0.03) [Stacking Classifier]


![](https://img-blog.csdnimg.cn/20200404174149659.png)

### 其他融合方法

加入新的特征


​    
    def Ensemble_add_feature(train, test, target, clfs):
        train_ = np.zeros((train.shape[0], len(clfs*2)))
        test_ = np.zeros((test.shape[0], len(clfs*2)))
    
        for j,clf in enumerate(clfs):
            clf.fit(train, target)
            y_train = clf.predict(train)
            y_test = clf.predict(test)
    
            # 生成新特征
            train_[:, j*2] = y_train**2
            test_[:, j*2] = y_test**2
            train_[:, j+1] = np.exp(y_train)
            test_[:, j+1] = np.exp(y_test)
            print('Method', j)
    
        train_ = pd.DataFrame(train_)
        test_ = pd.DataFrame(test_)
        return train_, test_


​    
​    
    from sklearn.model_selection import cross_val_score, train_test_split
    from sklearn.linear_model import LogisticRegression
    
    clf = LogisticRegression()
    data_0 = iris.data
    data = data_0[:100,:]
    
    target_0 = iris.target
    target = target_0[:100]
    
    x_train,x_test,y_train,y_test=train_test_split(data,target,test_size=0.3)
    x_train = pd.DataFrame(x_train) ; x_test = pd.DataFrame(x_test)
    
    #模型融合中使用到的各个单模型
    clfs = [LogisticRegression(),
            RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),
            ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),
            ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),
            GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]
    
    New_train, New_test = Ensemble_add_feature(x_train, x_test, y_train, clfs)
    
    clf = LogisticRegression()
    clf.fit(New_train, y_train)
    y_emb = clf.predict_proba(New_test)[:,1]
    
    print("Val auc Score of stacking: %f" % (roc_auc_score(y_test, y_emb)))


​    
​    
    Method 0
    Method 1
    Method 2
    Method 3
    Method 4
    Val auc Score of stacking: 1.000000


## 经验总结

  1. 结果层面的融合 

    * 最常见的融合方法，比如加权而哦那个和
  2. 模型层面的融合 

    * 涉及模型的堆叠和设计，比如Stacking
  3. 特征层面的融合 

    * 用多种模型训练时，将特征切分给不同的模型

