---
title: 数据挖掘实战（一）：赛题分析-二手车交易价格预测
date: 2020-03-25
permalink: /data-mining-practice-one.html
tags:
 - 数据挖掘
 - 二手车价格预测 
categories:
 - 数据挖掘

---



## 1 赛题概况

### 1.1 概况

赛题以预测二手车的交易价格为任务。

### 1.2 数据概况

该数据来自某交易平台的二手车交易记录，总数据量超过40w，包含31列变量信息，其中15列为匿名变量。为了保证比赛的公平性，将会从中抽取15万条作为训练集，5万条作为测试集A，5万条作为测试集B，同时会对name、model、brand和regionCode等信息进行脱敏。

### 1.3 评估指标

本赛题的评价标准为MAE(Mean Absolute Error): $$M A
E=\frac{\sum_{i=1}^{n}\left|y_{i}-\hat{y}_{i}\right|}{n}$$ **补充：**
分类算法常见的评估指标如下： \- 对于二类分类器/分类算法，评价指标主要有accuracy，
[Precision，Recall，F-score，Pr曲线]，ROC-AUC曲线。 \- 对于多类分类器/分类算法，评价指标主要有accuracy，
[宏平均和微平均，F-score]。 回归预测类常见的评估指标如下: \- 平均绝对误差（Mean Absolute
Error，MAE），均方误差（Mean Squared Error，MSE），平均绝对百分误差（Mean Absolute Percentage
Error，MAPE），均方根误差（Root Mean Squared Error）， R2（R-Square） 平均绝对误差（Mean Absolute
Error，MAE）： $$M A E=\frac{1}{N} \sum_{i=1}^{N}\left|y_{i}-\hat{y}
_{i}\right|$$ 均方误差（Mean Squared Error，MSE）： $$M S E=\frac{1}{N} \sum_
{i=1}^{N}\left(y_{i}-\hat{y} _{i}\right)^{2}$$ R2（R-Square）的公式： 残差平方和： $$S S_
{r e s}=\sum\left(y_{i}-\hat{y} _{i}\right)^{2}$$ 总平均值: $$S S_ {t o
t}=\sum\left(y_{i}-\bar{y} _{i}\right)^{2}$$ $R^2$表达式： $$R^{2}=1-\frac{S S_ {r
e s}}{S S_{t o t}}=1-\frac{\sum\left(y_{i}-\hat{y}
_{i}\right)^{2}}{\sum\left(y_ {i}-\bar{y}\right)^{2}}$$ 参数说明： $R^2$
用于度量因变量的变异中可由自变量解释部分所占的比例，取值范围是 0~1， $R^2$
越接近1,表明回归平方和占总平方和的比例越大,回归线与各观测点越接近，用x的变化来解释y值变化的部分就越多,回归的拟合程度就越好。 所以$R^2$
也称为拟合优度（Goodness of Fit）的统计量。

## 2 赛题分析

### 2.1 分析

  1. 回归问题
  2. 主要应用xgb、lgb、catboost，以及pandas、numpy、matplotlib、seabon、sklearn、keras等等数据挖掘常用库或者框架来进行数据挖掘任务。
  3. 通过EDA来挖掘数据的联系和自我熟悉数据。

### 2.2 代码示例

#### 数据读取


​    
    import pandas as pd
    import numpy as np
    
    # 载入测试集和训练集
    Train_data = pd.read_csv('used_car_train_20200313.csv', sep=' ')
    Test_data = pd.read_csv('used_car_testA_20200313.csv', sep=' ')
    
    print('Train data shape:', Train_data.shape)
    print('TestA data shape:', Test_data.shape)


​    
​    
    Train data shape: (150000, 31)
    TestA data shape: (50000, 30)


​    
​    
    Train_data.head()


#### 分类指标评价计算示例


​    
    # Accuracy
    import numpy as np
    from sklearn.metrics import accuracy_score
    
    y_pred = [0, 1, 0, 1]
    y_true = [0, 1, 1, 1]
    
    print('ACC:', accuracy_score(y_true, y_pred))


​    
​    
    ACC: 0.75


​    
​    
    # Precision, Recall, F1-score
    from sklearn import metrics
    
    y_pred = [0, 1, 0, 0]
    y_true = [0, 1, 0, 1]
    
    print('Precision:', metrics.precision_score(y_true, y_pred))
    print('Recall:', metrics.recall_score(y_true, y_pred))
    print('F1-score:', metrics.f1_score(y_true, y_pred))


​    
​    
    Precision 1.0
    Recall 0.5
    F1-score 0.6666666666666666


​    
​    
    # AUC
    import numpy as np
    from sklearn.metrics import roc_auc_score
    
    y_true = np.array([0, 0, 1, 1])
    y_scores = np.array([0.1, 0.4, 0.35, 0.8])
    
    print('AUC score:', roc_auc_score(y_true, y_scores))


​    
​    
    AUC score: 0.75


#### 回归指标评价计算示例


​    
    import numpy as np
    from sklearn import metrics
    
    # MAPE 需要自己实现
    def mape(y_true, y_pred):
        return np.mean(np.abs((y_pred - y_true) / y_true))
    
    y_true = np.array([1.0, 5.0, 4.0, 3.0, 2.0, 5.0, -3.0])
    y_pred = np.array([1.0, 4.5, 3.8, 3.2, 3.0, 4.8, -2.2])
    
    # MSE
    print('MSE:', metrics.mean_squared_error(y_true, y_pred))
    
    # RMSE
    print('RMSE:',np.sqrt(metrics.mean_squared_error(y_true, y_pred)))
    
    # MAE
    print('MAE:', metrics.mean_absolute_error(y_true, y_pred))
    
    # MAPE
    print('MAPE:', mape(y_true, y_pred))


​    
​    
    MSE: 0.2871428571428571
    RMSE: 0.5358571238146014
    MAE: 0.4142857142857143
    MAPE: 0.1461904761904762


​    
​    
    # R2-socre
    from sklearn.metrics import r2_score
    
    y_true = [3, -0.5, 2, 7]
    y_pred = [2.5, 0.0, 2, 8]
    print('R2-score:', r2_score(y_true, y_pred))


​    
​    
    R2-score: 0.9486081370449679


## 3 经验总结

**这一块觉得作者讲的很好，但没参加过比赛，并不是很能体会到其中的精髓，先记录于此**
作为切入一道赛题的基础，赛题理解是极其重要的，对于赛题的理解甚至会影响后续的特征工程构建以及模型的选择，最主要是会影响后续发展工作的方向，比如挖掘特征的方向或者存在问题解决问题的方向，对了赛题背后的思想以及赛题业务逻辑的清晰，也很有利于花费更少时间构建更为有效的特征模型，赛题理解要达到的地步是什么呢，把一道赛题转化为一种宏观理解的解决思路。
以下将从多方面对于此进行说明：

  1. 赛题理解究竟是理解什么： 理解赛题是不是把一道赛题的背景介绍读一遍就OK了呢？并不是的，理解赛题其实也是从直观上梳理问题，分析问题是否可行的方法，有多少可行度，赛题做的价值大不大，理清一道赛题要从背后的赛题背景引发的赛题任务理解其中的任务逻辑，可能对于赛题有意义的外在数据有哪些，并对于赛题数据有一个初步了解，知道现在和任务的相关数据有哪些，其中数据之间的关联逻辑是什么样的。 对于不同的问题，在处理方式上的差异是很大的。如果用简短的话来说，并且在比赛的角度或者做工程的角度，就是该赛题符合的问题是什么问题，大概要去用哪些指标，哪些指标是否会做到线上线下的一致性，是否有效的利于我们进一步的探索更高线上分数的线下验证方法，在业务上，你是否对很多原始特征有很深刻的了解，并且可以通过EDA来寻求他们直接的关系，最后构造出满意的特征。

  2. 有了赛题理解后能做什么： 在对于赛题有了一定的了解后，分析清楚了问题的类型性质和对于数据理解的这一基础上，是不是赛题理解就做完了呢? 并不是的，就像摸清了敌情后，我们至少就要有一些相应的理解分析，比如这题的难点可能在哪里，关键点可能在哪里，哪些地方可以挖掘更好的特征，用什么样得线下验证方式更为稳定，出现了过拟合或者其他问题，估摸可以用什么方法去解决这些问题，哪些数据是可靠的，哪些数据是需要精密的处理的，哪部分数据应该是关键数据（背景的业务逻辑下，比如CTR的题，一个寻常顾客大体会有怎么样的购买行为逻辑规律，或者风电那种题，如果机组比较邻近，相关一些风速，转速特征是否会很近似）。这时是在一个宏观的大体下分析的，有助于摸清整个题的思路脉络，以及后续的分析方向。

  3. 赛题理解的-评价指标： 为什么要把这部分单独拿出来呢，因为这部分会涉及后续模型预测中两个很重要的问题： 1． 本地模型的验证方式，很多情况下，线上验证是有一定的时间和次数限制的，所以在比赛中构建一个合理的本地的验证集和验证的评价指标是很关键的步骤，能有效的节省很多时间。 2． 不同的指标对于同样的预测结果是具有误差敏感的差异性的，比如AUC，logloss, MAE，RSME，或者一些特定的评价函数。是会有很大可能会影响后续一些预测的侧重点。

  4. 赛题背景中可能潜在隐藏的条件： 其实赛题中有些说明是很有利益-都可以在后续答辩中以及问题思考中所体现出来的，比如高效性要求，比如对于数据异常的识别处理，比如工序流程的差异性，比如模型运行的时间，比模型的鲁棒性，有些的意识是可以贯穿问题思考，特征，模型以及后续处理的，也有些会对于特征构建或者选择模型上有很大益处，反过来如果在模型预测效果不好，其实有时也要反过来思考，是不是赛题背景有没有哪方面理解不清晰或者什么其中的问题没考虑到。

## 4 问题记录

  1. EDA是什么？
  2. 分类评价指标的含义没有去理解？
  3. 作者写下的经验总结，后期需再看

